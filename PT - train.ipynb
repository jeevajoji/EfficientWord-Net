{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-10-28T14:30:30.146375Z",
     "iopub.status.busy": "2024-10-28T14:30:30.145663Z",
     "iopub.status.idle": "2024-10-28T14:30:50.550699Z",
     "shell.execute_reply": "2024-10-28T14:30:50.549726Z",
     "shell.execute_reply.started": "2024-10-28T14:30:30.146334Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -qU audiomentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T14:30:50.553210Z",
     "iopub.status.busy": "2024-10-28T14:30:50.552891Z",
     "iopub.status.idle": "2024-10-28T14:30:55.288462Z",
     "shell.execute_reply": "2024-10-28T14:30:55.287659Z",
     "shell.execute_reply.started": "2024-10-28T14:30:50.553179Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchaudio\n",
    "import librosa\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models\n",
    "import math\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T14:30:55.290384Z",
     "iopub.status.busy": "2024-10-28T14:30:55.289792Z",
     "iopub.status.idle": "2024-10-28T14:30:55.295304Z",
     "shell.execute_reply": "2024-10-28T14:30:55.294205Z",
     "shell.execute_reply.started": "2024-10-28T14:30:55.290336Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "SAMPLE_RATE = 16000\n",
    "AUDIO_WINDOW = 1.0  # seconds\n",
    "AUDIO_LENGTH = int(AUDIO_WINDOW * SAMPLE_RATE)\n",
    "LOG_MEL_MEAN = 1.4   \n",
    "LOG_MEL_STD = 1.184  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T14:30:55.296694Z",
     "iopub.status.busy": "2024-10-28T14:30:55.296370Z",
     "iopub.status.idle": "2024-10-28T14:30:55.310415Z",
     "shell.execute_reply": "2024-10-28T14:30:55.309574Z",
     "shell.execute_reply.started": "2024-10-28T14:30:55.296663Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "def random_crop(x: np.array, length=AUDIO_LENGTH) -> np.array:\n",
    "    assert x.shape[0] > length\n",
    "    front_bits = random.randint(0, x.shape[0] - length)\n",
    "    return x[front_bits:front_bits + length]\n",
    "\n",
    "def add_padding(x: np.array, length=AUDIO_LENGTH) -> np.array:\n",
    "    assert x.shape[0] < length\n",
    "    bit_count_to_be_added = length - x.shape[0]\n",
    "    front_bits = random.randint(0, bit_count_to_be_added)\n",
    "    new_x = np.pad(x, (front_bits, bit_count_to_be_added - front_bits))\n",
    "    assert new_x.shape[0] == length, f\"Error: Padded audio shape is {new_x.shape}, expected {length}\"\n",
    "    return new_x\n",
    "\n",
    "def remove_existing_padding(x: np.array) -> np.array:\n",
    "    non_zero = np.nonzero(x)[0]\n",
    "    return x[non_zero[0]:non_zero[-1] + 1] if len(non_zero) > 0 else x\n",
    "\n",
    "def fix_padding_issues(x: np.array, length=AUDIO_LENGTH) -> np.array:\n",
    "    x = remove_existing_padding(x)\n",
    "    if x.shape[0] > length:\n",
    "        return random_crop(x, length=length)\n",
    "    elif x.shape[0] < length:\n",
    "        return add_padding(x, length=length)\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "def add_noise(x: np.array, noise: np.array, noise_factor=0.4) -> np.array:\n",
    "    assert x.shape[0] == noise.shape[0]\n",
    "    out = (1 - noise_factor) * x / x.max() + noise_factor * (noise / noise.max())\n",
    "    return out / out.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T14:30:55.313107Z",
     "iopub.status.busy": "2024-10-28T14:30:55.312796Z",
     "iopub.status.idle": "2024-10-28T14:30:55.921302Z",
     "shell.execute_reply": "2024-10-28T14:30:55.920449Z",
     "shell.execute_reply.started": "2024-10-28T14:30:55.313075Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Audio augmentation\n",
    "from audiomentations import Compose, TimeStretch, PitchShift, Shift\n",
    "\n",
    "augmentation_pipeline = Compose([\n",
    "    TimeStretch(min_rate=0.8, max_rate=1.25, p=0.4),\n",
    "    PitchShift(min_semitones=-4, max_semitones=4, p=0.4),\n",
    "    Shift(min_shift=-0.5, max_shift=0.5,p=0.4),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T14:30:55.922835Z",
     "iopub.status.busy": "2024-10-28T14:30:55.922438Z",
     "iopub.status.idle": "2024-10-28T14:30:55.928811Z",
     "shell.execute_reply": "2024-10-28T14:30:55.927739Z",
     "shell.execute_reply.started": "2024-10-28T14:30:55.922803Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Mel spectrogram calculation\n",
    "def build_mel_spectrogram(waveform):\n",
    "    mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n",
    "        sample_rate=SAMPLE_RATE,\n",
    "        n_fft=500,\n",
    "        win_length=400,\n",
    "        hop_length=160,\n",
    "        n_mels=64,\n",
    "        f_min=50,\n",
    "        f_max=8000\n",
    "    )\n",
    "    log_mel_spectrogram = (torch.log(mel_spectrogram(waveform) + 1e-9) - LOG_MEL_MEAN) / LOG_MEL_STD\n",
    "    return log_mel_spectrogram.unsqueeze(0)  # channel dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T14:30:55.930717Z",
     "iopub.status.busy": "2024-10-28T14:30:55.930360Z",
     "iopub.status.idle": "2024-10-28T14:30:55.950119Z",
     "shell.execute_reply": "2024-10-28T14:30:55.949169Z",
     "shell.execute_reply.started": "2024-10-28T14:30:55.930683Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Custom Dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, chunked_noise_path, dataset_path, training=True, max_noise_factor=0.3, min_noise_factor=0.1):\n",
    "        self.chunked_noise_path = chunked_noise_path         #0.2 ,0.05\n",
    "        self.dataset_path = dataset_path\n",
    "        self.max_noise_factor = max_noise_factor\n",
    "        self.min_noise_factor = min_noise_factor\n",
    "        \n",
    "        self.words = [d for d in os.listdir(dataset_path) if not d.startswith('.')]\n",
    "        self.noise_types = [d for d in os.listdir(chunked_noise_path) if not d.startswith('.')]\n",
    "        \n",
    "        if training:\n",
    "            self.words = self.words[:int(0.9 * len(self.words))]\n",
    "        else:\n",
    "            self.words = self.words[int(0.9 * len(self.words)):]\n",
    "        \n",
    "        self.n = 2 * len(self.words)  # Positive and negative pairs\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.n\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        word1 = self.words[index // 2]\n",
    "        word2 = self.words[(index // 2 + index % 2) % (self.n // 2)]\n",
    "        \n",
    "        sample1 = random.choice([f for f in os.listdir(os.path.join(self.dataset_path, word1)) if not f.startswith('.')])\n",
    "        sample2 = random.choice([f for f in os.listdir(os.path.join(self.dataset_path, word2)) if not f.startswith('.')])\n",
    "        \n",
    "        voice_vector1, _ = librosa.load(os.path.join(self.dataset_path, word1, sample1), sr=SAMPLE_RATE)\n",
    "        voice_vector2, _ = librosa.load(os.path.join(self.dataset_path, word2, sample2), sr=SAMPLE_RATE)\n",
    "        \n",
    "        # Fix padding issues\n",
    "        voice_vector1 = fix_padding_issues(voice_vector1)\n",
    "        voice_vector2 = fix_padding_issues(voice_vector2)\n",
    "        \n",
    "        # Apply audio augmentation\n",
    "        voice_vector1 = augmentation_pipeline(samples=voice_vector1, sample_rate=SAMPLE_RATE)\n",
    "        voice_vector2 = augmentation_pipeline(samples=voice_vector2, sample_rate=SAMPLE_RATE)\n",
    "        \n",
    "        # Select random noise types\n",
    "        noise_type1, noise_type2 = random.sample(self.noise_types, 2)\n",
    "        noise1 = random.choice([f for f in os.listdir(os.path.join(self.chunked_noise_path, noise_type1)) if not f.startswith('.')])\n",
    "        noise2 = random.choice([f for f in os.listdir(os.path.join(self.chunked_noise_path, noise_type2)) if not f.startswith('.')])\n",
    "        \n",
    "        noise_vector1, _ = librosa.load(os.path.join(self.chunked_noise_path, noise_type1, noise1), sr=SAMPLE_RATE)\n",
    "        noise_vector2, _ = librosa.load(os.path.join(self.chunked_noise_path, noise_type2, noise2), sr=SAMPLE_RATE)\n",
    "        \n",
    "        # Apply noise\n",
    "        noise_factor1 = random.uniform(self.min_noise_factor, self.max_noise_factor)\n",
    "        noise_factor2 = random.uniform(self.min_noise_factor, self.max_noise_factor)\n",
    "        voice_with_noise1 = add_noise(voice_vector1, noise_vector1, noise_factor1)\n",
    "        voice_with_noise2 = add_noise(voice_vector2, noise_vector2, noise_factor2)\n",
    "        \n",
    "        # Generate mel spectrograms\n",
    "        spectrogram1 = build_mel_spectrogram(torch.tensor(voice_with_noise1))\n",
    "        spectrogram2 = build_mel_spectrogram(torch.tensor(voice_with_noise2))\n",
    "        \n",
    "        # Label: 1.0 for positive pairs, 0.0 for negative pairs\n",
    "        label = 1.0 if index % 2 == 0 else 0.0\n",
    "        \n",
    "        return spectrogram1, spectrogram2, torch.tensor(label, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T14:30:55.951813Z",
     "iopub.status.busy": "2024-10-28T14:30:55.951517Z",
     "iopub.status.idle": "2024-10-28T14:30:55.964294Z",
     "shell.execute_reply": "2024-10-28T14:30:55.963412Z",
     "shell.execute_reply.started": "2024-10-28T14:30:55.951783Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# SwiGLU Activation\n",
    "class SwiGLU(nn.Module):\n",
    "    def forward(self, x):\n",
    "        x, gate = x.chunk(2, dim=-1)\n",
    "        return F.silu(gate) * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T14:30:55.966012Z",
     "iopub.status.busy": "2024-10-28T14:30:55.965474Z",
     "iopub.status.idle": "2024-10-28T14:30:55.979575Z",
     "shell.execute_reply": "2024-10-28T14:30:55.978550Z",
     "shell.execute_reply.started": "2024-10-28T14:30:55.965971Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "\n",
    "class SwiGLU(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(SwiGLU, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_dim, output_dim * 2)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x1, x2 = x.chunk(2, dim=-1)\n",
    "        return x1 * F.silu(x2)\n",
    "\n",
    "# Siamese Network - ResNet-101 \n",
    "class SiameseNetworkResNet101(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetworkResNet101, self).__init__()\n",
    "        \n",
    "        self.base_network = models.resnet101(pretrained=True)\n",
    "        self.base_network.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        \n",
    "        modules = list(self.base_network.children())[:-1]\n",
    "        self.base_network = nn.Sequential(*modules)\n",
    "        \n",
    "        self.fc1 = nn.Linear(2048, 2048)\n",
    "        self.ln1 = nn.LayerNorm(2048)\n",
    "        self.dropout1 = nn.Dropout(p=0.3)     \n",
    "        \n",
    "        \n",
    "        self.swiglu = SwiGLU(2048, 1024)      \n",
    "        self.ln_swiglu = nn.LayerNorm(1024)\n",
    "        \n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.ln2 = nn.LayerNorm(512)\n",
    "        self.dropout2 = nn.Dropout(p=0.3)     \n",
    "        \n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.ln3 = nn.LayerNorm(256)\n",
    "        self.dropout3 = nn.Dropout(p=0.3)     \n",
    "        self.l2_norm = nn.functional.normalize\n",
    "\n",
    "    def forward_one(self, x):\n",
    "        x = self.base_network(x)\n",
    "        x = x.view(x.size(0), -1)  \n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.ln1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.swiglu(x)\n",
    "        x = self.ln_swiglu(x)   \n",
    "           \n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.ln2(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.ln3(x)\n",
    "        x = self.dropout3(x)\n",
    "        \n",
    "        x = self.l2_norm(x, p=2, dim=1)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, input1, input2):\n",
    "        output1 = self.forward_one(input1)\n",
    "        output2 = self.forward_one(input2)\n",
    "        return torch.pairwise_distance(output1, output2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T14:30:55.981122Z",
     "iopub.status.busy": "2024-10-28T14:30:55.980772Z",
     "iopub.status.idle": "2024-10-28T14:30:55.990403Z",
     "shell.execute_reply": "2024-10-28T14:30:55.989544Z",
     "shell.execute_reply.started": "2024-10-28T14:30:55.981081Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Loss function\n",
    "def triplet_loss(y_true, y_pred):\n",
    "    match_loss = y_true * -2.0 * torch.log(1 - y_pred/2)\n",
    "    mismatch_loss = torch.clamp((1 - y_true) * (-torch.log(y_pred/0.2)), min=0)\n",
    "    return torch.mean(match_loss + mismatch_loss)\n",
    "\n",
    "# Accuracy metric\n",
    "def accuracy(y_true, y_pred):\n",
    "    threshold_check = (y_pred <= 0.2).float()\n",
    "    return (y_true == threshold_check).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T14:30:55.992096Z",
     "iopub.status.busy": "2024-10-28T14:30:55.991737Z",
     "iopub.status.idle": "2024-10-28T14:30:56.007606Z",
     "shell.execute_reply": "2024-10-28T14:30:56.006773Z",
     "shell.execute_reply.started": "2024-10-28T14:30:55.992055Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train(model, train_loader, val_loader, num_epochs, device):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=1, factor=0.1, min_lr=1e-5)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}:')\n",
    "        \n",
    "        with tqdm(total=len(train_loader), desc=\"Training\") as progress_bar:\n",
    "            for batch_idx, (data1, data2, target) in enumerate(train_loader):\n",
    "                data1, data2, target = data1.to(device), data2.to(device), target.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                output = model(data1, data2)\n",
    "                loss = triplet_loss(target, output)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                train_loss += loss.item()\n",
    "                train_acc += accuracy(target, output)\n",
    "                \n",
    "                progress_bar.update(1) \n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        train_acc /= len(train_loader)\n",
    "        \n",
    "        val_loss, val_acc = validate(model, val_loader, device)\n",
    "        \n",
    "        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
    "        print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "        \n",
    "        # Save model every 5 epochs \n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            model_filename = f\"siamese_model_epoch_{epoch+1}_val_acc_{val_acc:.4f}.pth\"\n",
    "            torch.save(model.state_dict(), model_filename)\n",
    "            print(f\"Model saved as {model_filename}\")\n",
    "        \n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "def validate(model, val_loader, device):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_acc = 0\n",
    "    \n",
    "    with tqdm(total=len(val_loader), desc=\"Validation\") as progress_bar:  \n",
    "        with torch.no_grad():\n",
    "            for data1, data2, target in val_loader:\n",
    "                data1, data2, target = data1.to(device), data2.to(device), target.to(device)\n",
    "                \n",
    "                output = model(data1, data2)\n",
    "                loss = triplet_loss(target, output)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                val_acc += accuracy(target, output)\n",
    "                \n",
    "                progress_bar.update(1)  \n",
    "    \n",
    "    val_loss /= len(val_loader)\n",
    "    val_acc /= len(val_loader)\n",
    "    \n",
    "    return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T14:30:56.009068Z",
     "iopub.status.busy": "2024-10-28T14:30:56.008705Z",
     "iopub.status.idle": "2024-10-28T17:01:11.122484Z",
     "shell.execute_reply": "2024-10-28T17:01:11.121600Z",
     "shell.execute_reply.started": "2024-10-28T14:30:56.009025Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Main \n",
    "if __name__ == \"__main__\":\n",
    "    chunked_noise_path = r\"\" # path to noise (chunked)\n",
    "    dataset_path = r\"\"       # path to dataset\n",
    "    \n",
    "    train_dataset = CustomDataset(chunked_noise_path, dataset_path, training=True)\n",
    "    val_dataset = CustomDataset(chunked_noise_path, dataset_path, training=False)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = SiameseNetworkResNet101().to(device)\n",
    "    \n",
    "    num_epochs = 50\n",
    "    train(model, train_loader, val_loader, num_epochs, device)\n",
    "    \n",
    "    torch.save(model.state_dict(), \"siamese_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5926363,
     "sourceId": 9693257,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5935035,
     "sourceId": 9704512,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
